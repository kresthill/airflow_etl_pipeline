# ğŸ“Š Airflow ETL Pipeline for Stock Market Data  

This project is an **ETL pipeline built with Apache Airflow** that fetches real-time and historical stock market data from the **Alpha Vantage API**, transforms it, and loads it into a **PostgreSQL database** for analysis and reporting.  

---

## ğŸš€ Pipeline Architecture  

The workflow follows the standard **Extract â†’ Transform â†’ Load (ETL)** process:  

1. **Extract** â€“ Data is fetched from the Alpha Vantage API.  
2. **Transform** â€“ Data is cleaned, normalized, and structured for database insertion.  
3. **Load** â€“ Final data is stored in PostgreSQL tables.  

![ETL Pipeline](docs/etl_pipeline.png)  

---

## âš™ï¸ Features  
- Automated stock data ingestion from Alpha Vantage.  
- Task scheduling and orchestration with **Apache Airflow**.  
- PostgreSQL integration for structured storage.  
- Modular DAG design for scalability.  
- Easy visualization and monitoring via Airflow UI.  

---

## ğŸš€ Pipeline Overview  

Below is a visualization of the DAG as seen in the **Airflow UI pipeline graph**:

![Airflow Pipeline Graph](docs/AirflowGraph.png)

## ğŸ—„ï¸ Database Tables  

The pipeline creates a `time_series` table in PostgreSQL to store historical stock data.  

Example schema and sample rows:  

![Database Tables](docs/pipeline_tables.png)  

---

## ğŸ“‚ Project Structure  
airflow/
â”‚â”€â”€ dags/ # Airflow DAGs
â”‚ â””â”€â”€ etl_pipeline.py
â”‚â”€â”€ docs/ # Documentation and diagrams
â”‚ â”œâ”€â”€ etl_pipeline.png
â”‚ â””â”€â”€ pipeline_tables.png
â”‚â”€â”€ modules/ # Custom ETL modules
â”‚ â”œâ”€â”€ extract.py
â”‚ â”œâ”€â”€ transform.py
â”‚ â”œâ”€â”€ load.py
â”‚ â”œâ”€â”€ fetch.py
â”‚ â”œâ”€â”€ utils.py
â”‚ â””â”€â”€ init.py
â”‚â”€â”€ requirements.txt # Python dependencies
â”‚â”€â”€ README.md # Project documentation
â”‚â”€â”€ .gitignore # Git ignore rules
